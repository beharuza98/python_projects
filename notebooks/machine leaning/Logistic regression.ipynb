{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import codecademylib3\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "codecademyU = pd.read_csv('codecademyU.csv')\n",
    "\n",
    "# Define five_hour_studier below\n",
    "five_hour_studier = 0.05\n",
    "\n",
    "# Fit the logistic regression model\n",
    "hours_studied = codecademyU[['hours_studied']]\n",
    "passed_exam = codecademyU[['passed_exam']]\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "model = LogisticRegression()\n",
    "model.fit(hours_studied,passed_exam)\n",
    "\n",
    "# Plug sample data into fitted model\n",
    "sample_x = np.linspace(-16.65, 33.35, 300).reshape(-1,1)\n",
    "probability = model.predict_proba(sample_x)[:,1]\n",
    "\n",
    "# Plot exam data\n",
    "plt.scatter(hours_studied, passed_exam, color='black', s=100)\n",
    "\n",
    "# Plot logistic curve\n",
    "plt.plot(sample_x, probability, color='red', linewidth=3)\n",
    "\n",
    "# Customization for readability\n",
    "plt.xticks(fontsize = 30)\n",
    "plt.yticks(fontsize = 30)\n",
    "plt.axhline(y=0, color='k', linestyle='--')\n",
    "plt.axhline(y=1, color='k', linestyle='--')\n",
    "\n",
    "# Label plot and set limits\n",
    "plt.ylabel('probability passed', fontsize = 30)\n",
    "plt.xlabel('hours studied', fontsize = 30)\n",
    "plt.xlim(-1, 25)\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries and data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "codecademyU = pd.read_csv('codecademyU.csv')\n",
    "\n",
    "# Fit the logistic regression model\n",
    "hours_studied = codecademyU[['hours_studied']]\n",
    "passed_exam = codecademyU[['passed_exam']]\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "model = LogisticRegression()\n",
    "model.fit(hours_studied,passed_exam)\n",
    "\n",
    "# Save intercept and coef\n",
    "intercept = model.intercept_\n",
    "coef = model.coef_\n",
    "\n",
    "# Calculate log_odds here\n",
    "log_odds = intercept + coef * hours_studied\n",
    "print(log_odds)\n",
    "\n",
    "# Calculate pred_probability_passing here\n",
    "pred_probability_passing = np.exp(log_odds)/(1+ np.exp(log_odds))\n",
    "print(pred_probability_passing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting a model in sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import pandas and the data\n",
    "import pandas as pd\n",
    "codecademyU = pd.read_csv('codecademyU_2.csv')\n",
    "\n",
    "# Separate out X and y\n",
    "X = codecademyU[['hours_studied', 'practice_test']]\n",
    "y = codecademyU.passed_exam\n",
    "\n",
    "# Transform X\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X)\n",
    "X = scaler.transform(X)\n",
    "\n",
    "# Split data into training and testing sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state = 27)\n",
    "\n",
    "# Create and fit the logistic regression model here:\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "cc_lr=LogisticRegression()\n",
    "cc_lr.fit(X_train,y_train )\n",
    "print(cc_lr.coef_)\n",
    "print(cc_lr.intercept_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions in sklearn\n",
    "Using a trained model, we can predict whether new datapoints belong to the positive class (the group labeled as 1) using the .predict() method. The input is a matrix of features and the output is a vector of predicted labels, 1 or 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print out the predicted outcomes for the test data\n",
    "print(cc_lr.predict(X_test))\n",
    "\n",
    "# Print out the predicted probabilities for the test data\n",
    "print(cc_lr.predict_proba(X_test)[:,1])\n",
    "\n",
    "# Print out the true outcomes for the test data\n",
    "print(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion matrix\n",
    "When we fit a machine learning model, we need some way to evaluate it. Often, we do this by splitting our data into training and test datasets. We use the training data to fit the model; then we use the test set to see how well the model performs with new data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "print(confusion_matrix(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy, Recall, Precision, F1 Score\n",
    "Once we have a confusion matrix, there are a few different statistics we can use to summarize the four values in the matrix. These include accuracy, precision, recall, and F1 score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracy:\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(accuracy_score(y_true, y_pred))\n",
    "# output: 0.7\n",
    " \n",
    "# precision:\n",
    "from sklearn.metrics import precision_score\n",
    "print(precision_score(y_true, y_pred))\n",
    "# output: 0.67\n",
    " \n",
    "# recall: \n",
    "from sklearn.metrics import recall_score\n",
    "print(recall_score(y_true, y_pred))\n",
    "# output: 0.8\n",
    " \n",
    "# F1 score\n",
    "from sklearn.metrics import f1_score\n",
    "print(f1_score(y_true, y_pred))\n",
    "# output: 0.73"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A Logistic Regression model was trained on a datset of loan applications to predict whether or not a loan applicant would be approved. The three features of the model are age, income, and debt, and the derived coefficients are, respectively, 0.43, 1.24, and -0.85. The derived intercept is 0.42.\n",
    "\n",
    "What would the log-odds be if an applicantâ€™s age is 0.23, income is -0.12, and their debt is 0.33? (Remember, all of these values are normalized!)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To calculate the log-odds of an applicant being approved for a loan with the given values of normalized age, income, and debt, we need to use the logistic regression formula:\n",
    "\n",
    "log-odds = intercept + (coefficient of age * age) + (coefficient of income * income) + (coefficient of debt * debt)\n",
    "\n",
    "Substituting the given values, we get:\n",
    "\n",
    "log-odds = 0.42 + (0.43 * 0.23) + (1.24 * -0.12) + (-0.85 * 0.33)\n",
    "log-odds = 0.42 + 0.0989 - 0.1488 - 0.2805\n",
    "log-odds = 0.0916\n",
    "\n",
    "Therefore, the log-odds of an applicant with normalized age 0.23, normalized income -0.12, and normalized debt 0.33 being approved for a loan is 0.0916."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
